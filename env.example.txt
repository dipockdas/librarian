# Ollama models to use
# Embedding model for vectorizing text (for search)
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# LLM model for generating responses
OLLAMA_LLM_MODEL=mistral

# Qdrant configuration
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION=books

# Query settings
TOP_K=5